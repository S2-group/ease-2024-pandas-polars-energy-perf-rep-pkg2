library(car)
#make this example reproducible
set.seed(11)
qqPlot(Pandas_Data_Big$energy_usage)
qqPlot(Pandas_Data_Small$energy_usage)
qqPlot(Polars_Data_Big$energy_usage)
qqPlot(Polars_Data_Small$energy_usage)
install.packages("e1071")
library(e1071)
find_skewness <- function(data, name){
# Create a boxplot
boxplot(data, horizontal = TRUE, col = "lightblue", main = name)
# Calculate skewness
skew <- skewness(data)
# Determine skewness type
if (skew > 0) {
skew_type <- "Positively Skewed"
} else if (skew < 0) {
skew_type <- "Negatively Skewed"
} else {
skew_type <- "Symmetric (No skew)"
}
# Print summary statistics and skewness type
cat("Summary Statistics:\n")
summary(data)
cat("\nSkewness:", skew_type)
# Interpretation
if (skew > 0) {
cat("\n\nThe data is positively skewed, which means it has a long tail on the right side.")
} else if (skew < 0) {
cat("\n\nThe data is negatively skewed, which means it has a long tail on the left side.")
} else {
cat("\n\nThe data is symmetric, showing no skewness.")
}
}
find_skewness(Pandas_Data_Big$energy_usage, "PandasBig")
find_skewness(Pandas_Data_Small$energy_usage, "PandasSmall")
find_skewness(Pandas_Data_Big$energy_usage, "PolarsBig")
find_skewness(Pandas_Data_Small$energy_usage, "PolarsSmall")
install.packages("e1071")
install.packages("e1071")
library(e1071)
find_skewness <- function(data, name){
# Create a boxplot
# Calculate skewness
skew <- skewness(data)
# Determine skewness type
if (skew > 0) {
skew_type <- "Positively Skewed"
} else if (skew < 0) {
skew_type <- "Negatively Skewed"
} else {
skew_type <- "Symmetric (No skew)"
}
# Print summary statistics and skewness type
cat("Summary Statistics:\n")
summary(data)
cat("\nSkewness:", skew_type)
# Interpretation
if (skew > 0) {
cat("\n\nThe data is positively skewed, which means it has a long tail on the right side.")
} else if (skew < 0) {
cat("\n\nThe data is negatively skewed, which means it has a long tail on the left side.")
} else {
cat("\n\nThe data is symmetric, showing no skewness.")
}
}
find_skewness(Pandas_Data_Big$energy_usage, "PandasBig")
find_skewness(Pandas_Data_Small$energy_usage, "PandasSmall")
find_skewness(Pandas_Data_Big$energy_usage, "PolarsBig")
find_skewness(Pandas_Data_Small$energy_usage, "PolarsSmall")
# For looping the tests - different dataframe will be used:
# remove_outliers <- function(x) {
#   Q1 <- quantile(x, 0.25)
#   Q3 <- quantile(x, 0.75)
#   IQR_value <- IQR(x)#   lower_bound <- Q1 -  2*IQR_value
#   upper_bound <- Q3 +  2*IQR_value
#   return(x[x >= lower_bound & x <= upper_bound])
# }
# Assuming 'tpch' is your dataframe
# Define a function to remove outliers based on the Z-score
remove_and_prepare <- function(data, threshold = 3) {
# Calculate Z-scores
data
z_scores <- scale(data)
# Identify and remove outliers based on the Z-scores
data_no_outliers <- data[abs(z_scores) <= threshold]
return(data_no_outliers)
}
# Remove outliers from the 'tpch' dataframe
# Check the summary of the cleaned dataframe
# Identify outliers
Pandas_Big_no_outliers <- remove_and_prepare(Pandas_Data_Big$energy_usage)
Pandas_Small_no_outliers <- remove_and_prepare(Pandas_Data_Small$energy_usage)
Polars_Big_no_outliers <- remove_and_prepare(Polars_Data_Big$energy_usage)
Polars_Small_no_outliers <- remove_and_prepare(Polars_Data_Small$energy_usage)
qqPlot(Pandas_Big_no_outliers)
qqPlot(Pandas_Small_no_outliers)
qqPlot(Polars_Big_no_outliers)
qqPlot(Polars_Small_no_outliers)
# A low p-value (typically less than 0.05) indicates that the data significantly deviates from a normal distribution, providing evidence to reject the null hypothesis. In other words, it suggests non-normality.
#It is calculated during the Shapiro-Wilk test and is used to assess the degree of normality in the data. The value of W ranges between 0 and 1, where 1 indicates perfect normality.
#The smaller the W statistic, the stronger the evidence against the null hypothesis (the assumption that the data follows a normal distribution). Smaller W values suggest departures from normality.
shapiro_Pa_B <- shapiro.test(Pandas_Big_no_outliers)
shapiro_Pa_S <- shapiro.test(Pandas_Small_no_outliers)
shapiro_Po_B <- shapiro.test(Polars_Big_no_outliers)
shapiro_Po_S <- shapiro.test(Polars_Small_no_outliers)
cat("shapiro_Pandas_Big ",  "P_Value: ", shapiro_Pa_B$p.value, "W_Value: ", shapiro_Pa_B$statistic, "\n")
cat("shapiro_Pandas_Small ",  "P_Value: ", shapiro_Pa_S$p.value,"W_Value: ", shapiro_Pa_S$statistic, "\n")
cat("shapiro_Polars_Big ",  "P_Value: ", shapiro_Po_B$p.value,"W_Value: ", shapiro_Po_B$statistic, "\n")
cat("shapiro_Polars_Small ",  "P_Value: ", shapiro_Po_S$p.value,"W_Value: ", shapiro_Po_S$statistic, "\n")
Big <- wilcox.test(Pandas_Big_no_outliers, Polars_Big_no_outliers)
Small <- t.test(Pandas_Small_no_outliers, Polars_Small_no_outliers)
BigT <- wilcox.test(Pandas_Big_no_outliers, Polars_Big_no_outliers)
SmallT <- t.test(Pandas_Small_no_outliers, Polars_Small_no_outliers)
# Print the test result
cat("Small Dataset: ", "\n")
print(Small)
cat("Big Dataset: ", "\n")
print(Big)
cat("Small Dataset t: ", "\n")
print(SmallT)
cat("Big Dataset t: ", "\n")
print(BigT)
Big <- wilcox.test(Pandas_Big_no_outliers, Polars_Big_no_outliers)
Small <- t.test(Pandas_Small_no_outliers, Polars_Small_no_outliers)
# Print the test result
cat("Small Dataset: ", "\n")
print(Small)
cat("Big Dataset: ", "\n")
print(Big)
cliffs_delta <- function(x, y) {
n_x <- length(x)
n_y <- length(y)
# Calculate the number of positive (P) and negative (N) pairwise comparisons
P <- sum(outer(x, y, "<"))
N <- sum(outer(x, y, ">"))
# Calculate Cliff's Delta
delta <- (P - N) / (n_x * n_y)
return(delta)
}
cliffs_delta(Pandas_Big_no_outliers, Polars_Big_no_outliers)
cliffs_delta <- function(x, y) {
n_x <- length(x)
n_y <- length(y)
# Calculate the number of positive (P) and negative (N) pairwise comparisons
P <- sum(outer(x, y, "<"))
N <- sum(outer(x, y, ">"))
# Calculate Cliff's Delta
delta <- (P - N) / (n_x * n_y)
return(delta)
}
# Calculate Cliff's Delta for your datasets
cliffs_delta_value <- cliffs_delta(Pandas_Big_no_outliers, Polars_Big_no_outliers)
# Print the result
cat("Cliff's Delta:", cliffs_delta_value, "\n")
Big <- wilcox.test(Pandas_Big_no_outliers, Polars_Big_no_outliers)
Small <- wolcox.test(Pandas_Small_no_outliers, Polars_Small_no_outliers)
Big <- wilcox.test(Pandas_Big_no_outliers, Polars_Big_no_outliers)
Small <- wilcox.test(Pandas_Small_no_outliers, Polars_Small_no_outliers)
# Print the test result
cat("Small Dataset: ", "\n")
print(Small)
cat("Big Dataset: ", "\n")
print(Big)
cliffs_delta <- function(x, y) {
n_x <- length(x)
n_y <- length(y)
# Calculate the number of positive (P) and negative (N) pairwise comparisons
P <- sum(outer(x, y, "<"))
N <- sum(outer(x, y, ">"))
# Calculate Cliff's Delta
delta <- (P - N) / (n_x * n_y)
return(delta)
}
# Calculate Cliff's Delta for your datasets
cliffs_delta_value <- cliffs_delta(Pandas_Big_no_outliers, Polars_Big_no_outliers)
# Print the result
cat("Cliff's Delta:", cliffs_delta_value, "\n")
# Calculate Cliff's Delta for your datasets
cliffs_delta_value <- cliffs_delta(Pandas_Big_no_outliers, Polars_Big_no_outliers)
# Print the result
cat("Cliff's Delta:", cliffs_delta_value, "\n")
cliffs_delta <- function(x, y) {
n_x <- length(x)
n_y <- length(y)
# Calculate the number of positive (P) and negative (N) pairwise comparisons
P <- sum(outer(x, y, "<"))
N <- sum(outer(x, y, ">"))
# Calculate Cliff's Delta
delta <- (P - N) / (n_x * n_y)
return(delta)
}
# Calculate Cliff's Delta for your datasets
cliffs_delta_value <- cliffs_delta(Pandas_Big_no_outliers, Polars_Big_no_outliers)
# Print the result
cat("Cliff's Delta:", cliffs_delta_value, "\n")
# Calculate Cliff's Delta for your datasets
cliffs_delta_value <- cliffs_delta(Pandas_Small_no_outliers, Polars_Small_no_outliers)
# Print the result
cat("Cliff's Delta:", cliffs_delta_value, "\n")
# For looping the tests - different dataframe will be used:
# remove_outliers <- function(x) {
#   Q1 <- quantile(x, 0.25)
#   Q3 <- quantile(x, 0.75)
#   IQR_value <- IQR(x)#   lower_bound <- Q1 -  2*IQR_value
#   upper_bound <- Q3 +  2*IQR_value
#   return(x[x >= lower_bound & x <= upper_bound])
# }
# Assuming 'tpch' is your dataframe
# Define a function to remove outliers based on the Z-score
remove_and_prepare <- function(data, threshold = 3) {
# Calculate Z-scores
data
z_scores <- scale(data)
# Identify and remove outliers based on the Z-scores
data_no_outliers <- data[abs(z_scores) <= threshold]
return(data_no_outliers)
}
# Remove outliers from the 'tpch' dataframe
# Check the summary of the cleaned dataframe
# Identify outliers
Pandas_Big_no_outliers <- remove_and_prepare(Pandas_Data_Big$energy_usage)
Pandas_Small_no_outliers <- remove_and_prepare(Pandas_Data_Small$energy_usage)
Polars_Big_no_outliers <- remove_and_prepare(Polars_Data_Big$energy_usage)
Polars_Small_no_outliers <- remove_and_prepare(Polars_Data_Small$energy_usage)
qqPlot(Pandas_Big_no_outliers)
qqPlot(Pandas_Small_no_outliers)
qqPlot(Polars_Big_no_outliers)
qqPlot(Polars_Small_no_outliers)
# A low p-value (typically less than 0.05) indicates that the data significantly deviates from a normal distribution, providing evidence to reject the null hypothesis. In other words, it suggests non-normality.
#It is calculated during the Shapiro-Wilk test and is used to assess the degree of normality in the data. The value of W ranges between 0 and 1, where 1 indicates perfect normality.
#The smaller the W statistic, the stronger the evidence against the null hypothesis (the assumption that the data follows a normal distribution). Smaller W values suggest departures from normality.
shapiro_Pa_B <- shapiro.test(Pandas_Big_no_outliers)
shapiro_Pa_S <- shapiro.test(Pandas_Small_no_outliers)
shapiro_Po_B <- shapiro.test(Polars_Big_no_outliers)
shapiro_Po_S <- shapiro.test(Polars_Small_no_outliers)
cat("shapiro_Pandas_Big ",  "P_Value: ", shapiro_Pa_B$p.value, "W_Value: ", shapiro_Pa_B$statistic, "\n")
cat("shapiro_Pandas_Small ",  "P_Value: ", shapiro_Pa_S$p.value,"W_Value: ", shapiro_Pa_S$statistic, "\n")
cat("shapiro_Polars_Big ",  "P_Value: ", shapiro_Po_B$p.value,"W_Value: ", shapiro_Po_B$statistic, "\n")
cat("shapiro_Polars_Small ",  "P_Value: ", shapiro_Po_S$p.value,"W_Value: ", shapiro_Po_S$statistic, "\n")
Big <- wilcox.test(Pandas_Big_no_outliers, Polars_Big_no_outliers)
Small <- wilcox.test(Pandas_Small_no_outliers, Polars_Small_no_outliers)
# Print the test result
cat("Small Dataset: ", "\n")
print(Small)
cat("Big Dataset: ", "\n")
print(Big)
Big <- wilcox.test(Pandas_Big_no_outliers, Polars_Big_no_outliers)
Small <- wilcox.test(Pandas_Small_no_outliers, Polars_Small_no_outliers)
# Print the test result
cat("Small Dataset: ", "\n")
print(Small)
cat("Big Dataset: ", "\n")
print(Big)
Small <- wilcox.test(Pandas_Small_no_outliers, Polars_Small_no_outliers)
# Print the test result
cat("Small Dataset: ", "\n")
print(Small)
cat("Big Dataset: ", "\n")
print(Big)
Big <- wilcox.test(Pandas_Big_no_outliers, Polars_Big_no_outliers)
Small <- wilcox.test(Pandas_Small_no_outliers, Polars_Small_no_outliers)
# Print the test result
cat("Small Dataset: ", "\n")
print(Small)
cat("Big Dataset: ", "\n")
print(Big)
cliffs_delta <- function(x, y) {
n_x <- length(x)
n_y <- length(y)
# Calculate the number of positive (P) and negative (N) pairwise comparisons
P <- sum(outer(x, y, "<"))
N <- sum(outer(x, y, ">"))
# Calculate Cliff's Delta
delta <- (P - N) / (n_x * n_y)
return(delta)
}
# Calculate Cliff's Delta for your datasets
cliffs_delta_value <- cliffs_delta(Pandas_Big_no_outliers, Polars_Big_no_outliers)
# Print the result
cat("Cliff's Delta:", cliffs_delta_value, "\n")
# Calculate Cliff's Delta for your datasets
cliffs_delta_value <- cliffs_delta(Pandas_Small_no_outliers, Polars_Small_no_outliers)
# Print the result
cat("Cliff's Delta:", cliffs_delta_value, "\n")
cliffs_delta <- function(x, y) {
n_x <- length(x)
n_y <- length(y)
# Calculate the number of positive (P) and negative (N) pairwise comparisons
P <- sum(outer(x, y, "<"))
N <- sum(outer(x, y, ">"))
# Calculate Cliff's Delta
delta <- (P - N) / (n_x * n_y)
return(delta)
}
# Calculate Cliff's Delta for your datasets
cliffs_delta_value_big <- cliffs_delta(Pandas_Big_no_outliers, Polars_Big_no_outliers)
# Print the result
cat("Cliff's Delta Big Dataset:", cliffs_delta_value_big, "\n")
# Calculate Cliff's Delta for your datasets
cliffs_delta_value_small <- cliffs_delta(Pandas_Small_no_outliers, Polars_Small_no_outliers)
# Print the result
cat("Cliff's Delta Small Dataset:", cliffs_delta_value_small, "\n")
Big <- wilcox.test(Pandas_Big_no_outliers, Polars_Big_no_outliers, paired = TRUE, two)
Big <- wilcox.test(Pandas_Big_no_outliers, Polars_Big_no_outliers, paired = TRUE)
Big <- wilcox.test(Pandas_Data_Big$energy_usage, Polars_Data_Big$energy_usage, paired = TRUE)
Big <- wilcox.test(Pandas_Data_Big$energy_usage, Polars_Data_Big$energy_usage, paired = TRUE)
Big <- wilcox.test(Pandas_Data_Big$energy_usage, Polars_Data_Big$energy_usage, paired = TRUE)
Big <- wilcox.test(Pandas_Data_Big$energy_usage, Polars_Data_Big$energy_usage, paired = TRUE)
Big <- wilcox.test(Pandas_Data_Big$energy_usage, Polars_Data_Big$energy_usage, paired = TRUE)
Big <- wilcox.test(Pandas_Data_Big$energy_usage, Polars_Data_Big$energy_usage, paired = TRUE)
Big <- wilcox.test(Pandas_Data_Big$energy_usage, Polars_Data_Big$energy_usage, paired = TRUE)
Big <- wilcox.test(Pandas_Data_Big$energy_usage, Polars_Data_Big$energy_usage, paired = TRUE)
knitr::opts_chunk$set(echo = TRUE)
options(repos = c(CRAN = "https://cran.rstudio.com/"))
install.packages("tidyverse")
install.packages("dplyr")
if (!require("ggplot2")) install.packages("ggplot2")
# Load the ggplot2 library if not already loaded
library(ggplot2)
library("tidyverse")
library("dplyr")
install.packages("outlierDetection")
library(outlierDetection)
# Mean and Mode
tpch <- read.csv2("./Data/dataFiltered.csv")
#tpch[is.na(tpch)] <- 0
print(head(tpch))
Pandas_Data_Small <- tpch %>%
filter(library == "Pandas" & dataframe_size == "Small")
Pandas_Data_Big <- tpch %>%
filter(library == "Pandas" & dataframe_size == "Big")
Polars_Data_Small <- tpch %>%
filter(library == "Polars" & dataframe_size == "Small")
Polars_Data_Big <- tpch %>%
filter(library == "Polars" & dataframe_size == "Big")
Pandas_Small_mean_energy <- mean(Pandas_Data_Small$energy_usage)
Pandas_Big_mean_energy <- mean(Pandas_Data_Big$energy_usage)
Polars_Small_mean_energy <- mean(Polars_Data_Small$energy_usage)
Polars_Big_mean_energy <- mean(Polars_Data_Big$energy_usage)
Pandas_Small_median_energy <- median(Pandas_Data_Small$energy_usage)
Pandas_Big_median_energy <- median(Pandas_Data_Big$energy_usage)
Polars_Small_median_energy <- median(Polars_Data_Small$energy_usage)
Polars_Big_median_energy <- median(Polars_Data_Big$energy_usage)
cat("Mean Analysis:","\n")
cat("Pandas_Small_mean_energy:", Pandas_Small_mean_energy, "\n")
cat("Pandas_Big_mean_energy:", Pandas_Big_mean_energy, "\n")
cat("Polars_Small_mean_energy:", Polars_Small_mean_energy, "\n")
cat("Polars_Big_mean_energy:", Polars_Big_mean_energy, "\n\n")
cat("Median Analysis:","\n")
cat("Pandas_Small_median_energy:", Pandas_Small_median_energy, "\n")
cat("Pandas_Big_median_energy:", Pandas_Big_median_energy, "\n")
cat("Polars_Small_median_energy:", Polars_Small_median_energy, "\n")
cat("Polars_Big_median_energy:", Polars_Big_median_energy, "\n\n")
# Variance and Standard Deviation
Pandas_Small_sd_energy <- sd(Pandas_Data_Small$energy_usage)
Pandas_Big_sd_energy <- sd(Pandas_Data_Big$energy_usage)
Polars_Small_sd_energy <- sd(Polars_Data_Small$energy_usage)
Polars_Big_sd_energy <- sd(Polars_Data_Big$energy_usage)
Pandas_Small_var_energy <- var(Pandas_Data_Small$energy_usage)
Pandas_Big_var_energy <- var(Pandas_Data_Big$energy_usage)
Polars_Small_var_energy <- var(Polars_Data_Small$energy_usage)
Polars_Big_var_energy <- var(Polars_Data_Big$energy_usage)
cat("Standard Deviation:","\n")
cat("Pandas_Small_sd_energy:", Pandas_Small_sd_energy, "\n")
cat("Pandas_Big_sd_energy:", Pandas_Big_sd_energy, "\n")
cat("Polars_Small_sd_energy:", Polars_Small_sd_energy, "\n")
cat("Polars_Big_sd_energy:", Polars_Big_sd_energy, "\n\n")
cat("Variance:","\n")
cat("Pandas_Small_var_energy:", Pandas_Small_var_energy, "\n")
cat("Pandas_Big_var_energy:", Pandas_Big_var_energy, "\n")
cat("Polars_Small_var_energy:", Polars_Small_var_energy, "\n")
cat("Polars_Big_var_energy:", Polars_Big_var_energy, "\n\n")
# Data Distribution
# Create a density plot for energy_usage for dataframe_size = small
density_plot <- function(dataset, title, x, y){
ggplot(dataset, aes(x = Values, fill = Distribution)) +
geom_density(alpha = 0.5) +
labs(
title = title,
x = x,
y = y
) +
theme_minimal()
}
violin_boxplot <- function(dataset, title, x, y) {
ggplot(dataset, aes(x = Distribution, y = Values, fill = Distribution)) +
geom_violin(alpha = 0.5) +
geom_boxplot(width = 0.1, outlier.shape = NA) +
scale_fill_manual(values = c("Pandas" = "lightblue", "Polars" = "pink")) +
labs(
title = title,
x = x,
y = y
) +
theme_minimal()
}
# newTry <- Pandas_Data_Big
# newTry$energy_usage <-  Pandas_Data_Big$energy_usage
# newTry2 <- Pandas_Data_Small
# newTry2$energy_usage <-  Pandas_Data_Small$energy_usage
# newTry3 <- Polars_Data_Big
# newTry3$energy_usage <-  Polars_Data_Big$energy_usage
# newTry4 <- Polars_Data_Small
# newTry4$energy_usage <-  Polars_Data_Small$energy_usage
Small_Block <- data.frame(
Distribution = c(rep("Pandas", length(Pandas_Data_Small$energy_usage)), rep("Polars", length(Polars_Data_Small$energy_usage))),
Values = c(Pandas_Data_Small$energy_usage, Polars_Data_Small$energy_usage)
)
Big_Block <- data.frame(
Distribution = c(rep("Pandas", length(Pandas_Data_Big$energy_usage)), rep("Polars", length(Polars_Data_Big$energy_usage))),
Values = c(Pandas_Data_Big$energy_usage, Polars_Data_Big$energy_usage)
)
density_plot(dataset=Small_Block, title="Pandas - Density Plot of Energy Usage for Dataframe Size: Big", x="Energy Usage", y="Density")
density_plot(dataset=Big_Block, title="Pandas - Density Plot of Energy Usage for Dataframe Size: Small", x="Energy Usage", y="Density")
violin_boxplot(dataset=Small_Block, title="Pandas - Density Plot of Energy Usage for Dataframe Size: Big", x="Energy Usage", y="Density")
violin_boxplot(dataset=Big_Block, title="Pandas - Density Plot of Energy Usage for Dataframe Size: Small", x="Energy Usage", y="Density")
library(car)
#make this example reproducible
set.seed(11)
qqPlot(Pandas_Data_Big$energy_usage)
qqPlot(Pandas_Data_Small$energy_usage)
qqPlot(Polars_Data_Big$energy_usage)
qqPlot(Polars_Data_Small$energy_usage)
install.packages("e1071")
library(e1071)
find_skewness <- function(data, name){
# Create a boxplot
# Calculate skewness
skew <- skewness(data)
# Determine skewness type
if (skew > 0) {
skew_type <- "Positively Skewed"
} else if (skew < 0) {
skew_type <- "Negatively Skewed"
} else {
skew_type <- "Symmetric (No skew)"
}
# Print summary statistics and skewness type
cat("Summary Statistics:\n")
summary(data)
cat("\nSkewness:", skew_type)
# Interpretation
if (skew > 0) {
cat("\n\nThe data is positively skewed, which means it has a long tail on the right side.")
} else if (skew < 0) {
cat("\n\nThe data is negatively skewed, which means it has a long tail on the left side.")
} else {
cat("\n\nThe data is symmetric, showing no skewness.")
}
}
find_skewness(Pandas_Data_Big$energy_usage, "PandasBig")
find_skewness(Pandas_Data_Small$energy_usage, "PandasSmall")
find_skewness(Pandas_Data_Big$energy_usage, "PolarsBig")
find_skewness(Pandas_Data_Small$energy_usage, "PolarsSmall")
# For looping the tests - different dataframe will be used:
# remove_outliers <- function(x) {
#   Q1 <- quantile(x, 0.25)
#   Q3 <- quantile(x, 0.75)
#   IQR_value <- IQR(x)#   lower_bound <- Q1 -  2*IQR_value
#   upper_bound <- Q3 +  2*IQR_value
#   return(x[x >= lower_bound & x <= upper_bound])
# }
# Assuming 'tpch' is your dataframe
# Define a function to remove outliers based on the Z-score
remove_and_prepare <- function(data, threshold = 3) {
# Calculate Z-scores
data
z_scores <- scale(data)
# Identify and remove outliers based on the Z-scores
data_no_outliers <- data[abs(z_scores) <= threshold]
return(data_no_outliers)
}
# Remove outliers from the 'tpch' dataframe
# Check the summary of the cleaned dataframe
# Identify outliers
Pandas_Big_no_outliers <- remove_and_prepare(Pandas_Data_Big$energy_usage)
Pandas_Small_no_outliers <- remove_and_prepare(Pandas_Data_Small$energy_usage)
Polars_Big_no_outliers <- remove_and_prepare(Polars_Data_Big$energy_usage)
Polars_Small_no_outliers <- remove_and_prepare(Polars_Data_Small$energy_usage)
qqPlot(Pandas_Big_no_outliers)
qqPlot(Pandas_Small_no_outliers)
qqPlot(Polars_Big_no_outliers)
qqPlot(Polars_Small_no_outliers)
# A low p-value (typically less than 0.05) indicates that the data significantly deviates from a normal distribution, providing evidence to reject the null hypothesis. In other words, it suggests non-normality.
#It is calculated during the Shapiro-Wilk test and is used to assess the degree of normality in the data. The value of W ranges between 0 and 1, where 1 indicates perfect normality.
#The smaller the W statistic, the stronger the evidence against the null hypothesis (the assumption that the data follows a normal distribution). Smaller W values suggest departures from normality.
shapiro_Pa_B <- shapiro.test(Pandas_Big_no_outliers)
shapiro_Pa_S <- shapiro.test(Pandas_Small_no_outliers)
shapiro_Po_B <- shapiro.test(Polars_Big_no_outliers)
shapiro_Po_S <- shapiro.test(Polars_Small_no_outliers)
cat("shapiro_Pandas_Big ",  "P_Value: ", shapiro_Pa_B$p.value, "W_Value: ", shapiro_Pa_B$statistic, "\n")
cat("shapiro_Pandas_Small ",  "P_Value: ", shapiro_Pa_S$p.value,"W_Value: ", shapiro_Pa_S$statistic, "\n")
cat("shapiro_Polars_Big ",  "P_Value: ", shapiro_Po_B$p.value,"W_Value: ", shapiro_Po_B$statistic, "\n")
cat("shapiro_Polars_Small ",  "P_Value: ", shapiro_Po_S$p.value,"W_Value: ", shapiro_Po_S$statistic, "\n")
Big <- wilcox.test(Pandas_Data_Big$energy_usage, Polars_Data_Big$energy_usage, paired = TRUE)
print(length(Pandas_Data_Big$energy_usage))
print(length(Polars_Data_Big$energy_usage))
Big <- wilcox.test(Pandas_Data_Big$energy_usage, Polars_Data_Big$energy_usage, paired = TRUE)
knitr::opts_chunk$set(echo = TRUE)
options(repos = c(CRAN = "https://cran.rstudio.com/"))
install.packages("tidyverse")
install.packages("dplyr")
if (!require("ggplot2")) install.packages("ggplot2")
# Load the ggplot2 library if not already loaded
library(ggplot2)
library("tidyverse")
library("dplyr")
install.packages("outlierDetection")
library(outlierDetection)
savehistory("~/0 - Meine Dateien/Software Engineering for Green Deal/Amsterdam/R-ANalysis_of_project/history.Rhistory")
